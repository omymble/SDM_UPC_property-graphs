{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e141311d-3140-438e-93a3-4d9e4d572c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import math\n",
    "import glob\n",
    "import lorem\n",
    "import random\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4ca3f-82ef-4456-92be-66efa4200cf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### This Notebook delivers the initialization stages of generating and transforming the DBLP dataset suitable for import into Neo4j. It contains pre-processing necessary for both the initial and evolved graph models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5e57c-c6db-4252-901d-cb27d46fef23",
   "metadata": {},
   "source": [
    "### A2 Instantiating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330a7fe-950d-419a-8a43-4202ae719ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generating DBLP files"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32729306-cffe-44e5-9810-3bff4d58b9a4",
   "metadata": {},
   "source": [
    "# Obtain latest DBLP from website\n",
    "https://dblp.uni-trier.de/xml/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53badb77-5c9e-4480-90f2-5634bbcfa4fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Converting XML file to CSV\n",
    "# Source: https://github.com/ThomHurks/dblp-to-csv\n",
    "\n",
    "## preferable run in bin/bash\n",
    "chmod +x XMLToCSV.py\n",
    "./XMLToCSV.py --annotate --neo4j dblp.xml dblp.dtd output.csv --relations author:authored_by journal:published_in publisher:published_by school:submitted_at editor:edited_by cite:has_citation series:is_part_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9c5c59-aca2-4614-ae25-ff6ac130c8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DXML\\\\output_article.csv',\n",
       " 'DXML\\\\output_article_header.csv',\n",
       " 'DXML\\\\output_author.csv',\n",
       " 'DXML\\\\output_author_authored_by.csv',\n",
       " 'DXML\\\\output_book.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All CSV files generated from the DBLP XML\n",
    "\n",
    "## All files and directories ending with .csv:\n",
    "files = (glob.glob(\"DXML/*.csv\"))\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e75d825d-6247-4184-bb05-f5f23f8cde1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1fd59c5-489e-4da6-b7ae-cf738395736d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PRE-PROCESSING DBLP DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a5808-89d2-440d-a9b2-f70889ee64aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:CITE NODE) --> [:CITE_HAS_CITATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595a3b48-65a7-48ec-b2e7-2e7af7da0b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>author-aux:string</th>\n",
       "      <th>author-orcid:string[]</th>\n",
       "      <th>booktitle:string</th>\n",
       "      <th>cdate:date</th>\n",
       "      <th>cdrom:string</th>\n",
       "      <th>cite:string[]</th>\n",
       "      <th>cite-label:string[]</th>\n",
       "      <th>crossref:string</th>\n",
       "      <th>...</th>\n",
       "      <th>publnr:string</th>\n",
       "      <th>publtype:string</th>\n",
       "      <th>sub:string[]</th>\n",
       "      <th>sup:string[]</th>\n",
       "      <th>title:string</th>\n",
       "      <th>title-bibtex:string</th>\n",
       "      <th>tt:string[]</th>\n",
       "      <th>url:string[]</th>\n",
       "      <th>volume:string</th>\n",
       "      <th>year:int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>informal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article:ID author:string[] author-aux:string author-orcid:string[]  \\\n",
       "0           5             NaN               NaN                   NaN   \n",
       "\n",
       "  booktitle:string cdate:date cdrom:string cite:string[] cite-label:string[]  \\\n",
       "0              NaN        NaN          NaN           NaN                 NaN   \n",
       "\n",
       "  crossref:string  ... publnr:string publtype:string sub:string[]  \\\n",
       "0             NaN  ...           NaN        informal          NaN   \n",
       "\n",
       "  sup:string[] title:string title-bibtex:string tt:string[] url:string[]  \\\n",
       "0          NaN            …                 NaN         NaN          NaN   \n",
       "\n",
       "  volume:string year:int  \n",
       "0           NaN      NaN  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all data from articles \n",
    "\n",
    "## Article headers\n",
    "with open('DXML\\\\output_article_header.csv') as f:\n",
    "    article_header = f.readline().split(';');\n",
    "    #print(article_header[1:5])\n",
    "\n",
    "## Articles in dataset\n",
    "articles = pd.read_csv('DXML\\\\output_article.csv', header=0, names=article_header, sep=';');\n",
    "\n",
    "## Display articles\n",
    "articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2231c9e-234c-4caf-ac7b-7f91328dd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only 10000 articles\n",
    "art_sel = articles[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdaa7be1-d9ff-4492-a396-c4d284d55288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the articles into Journals, Conferences, Workshops or None of thw above\n",
    "## we assume all papers are accepted but with a ditribution of 95% for True (accepted)\n",
    "art_sel['sup:string[]'] = np.random.choice(['J', 'C', 'W', 'N'], size=len(art_sel), p=[0.35, 0.45, 0.12, 0.08])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639f022c-e1d9-4c43-b0ea-e1a11e71bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for cite and citation\n",
    "# split the dataframe into two parts i.e 0.33% for cite\n",
    "art_citation, art_cite = train_test_split(art_sel, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2586f53e-299d-4b51-a5af-13a7e4f533a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure articles in citation are written before cite articles\n",
    "\n",
    "## create a list of year values to assign randomly from 2017-2019\n",
    "values = [2017, 2018, 2019]\n",
    "\n",
    "## randomly assign the values as a new column in the DataFrame\n",
    "art_citation['year:int'] = np.random.RandomState(42).choice(values, len(art_citation))\n",
    "\n",
    "#art_citation.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d832e3e-5a0d-4c67-b80b-94302587d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure articles in cite are written after citation articles\n",
    "\n",
    "# create a list of values to assign randomly from 2021-2022\n",
    "values = [2020, 2021, 2022]\n",
    "\n",
    "# randomly assign the values as a new column in the DataFrame\n",
    "art_cite['year:int'] = np.random.RandomState(42).choice(values, len(art_cite))\n",
    "\n",
    "#art_cite.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4876511d-f5dc-47a1-b30f-3f711fdc2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the edge cite has citation\n",
    "\n",
    "## Selecting citation\n",
    "cite_cita = art_citation[['author-aux:string', 'article:ID']]\n",
    "\n",
    "## Replicate the citation df so that each article has at least 2 citations\n",
    "cite_cita = pd.concat([cite_cita]*2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1176ea82-05e4-4faa-8ca0-2bb95a8a0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomly assign cite articles to citation\n",
    "\n",
    "# obtain set list of cite\n",
    "ref_in_art_cite = list(set(list(art_cite['article:ID'])))\n",
    "\n",
    "# Define function to randomly assignIDs\n",
    "def assign_no():\n",
    "    return random.choice(ref_in_art_cite)\n",
    "\n",
    "# Apply function to create edition venue column with randomly assigned cities\n",
    "cite_cita['author-aux:string'] = cite_cita.apply(lambda x: assign_no(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f114b14f-aec8-43dc-a249-6de461ce5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match Neo4j requirememts\n",
    "cite_cita = cite_cita.rename(columns={'author-aux:string': 'articleid',\n",
    "                                     'article:ID': 'citaid'})\n",
    "\n",
    "cite_cita.drop_duplicates(subset=['articleid','citaid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "053234b1-adce-4033-b528-ac8255d7e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "cite_cita.to_csv(path_or_buf='Mains/cite_has_citation.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa77ff2-82e0-4498-bcba-38dda9b5d7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free Memory\n",
    "del art_sel, articles\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669de9e-5c1e-4ce0-a24a-b4b1d6e9dc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8faceb88-743f-4519-b576-e7b342363cfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:ARTICLE NODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bc0f496-a6bc-4e56-8828-bc0c32fb13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total papers are: 10000\n"
     ]
    }
   ],
   "source": [
    "## Articles selected\n",
    "articles_selected = pd.concat([art_citation, art_cite])\n",
    "\n",
    "ref_in_cite = list(set(list(articles_selected['article:ID'])))\n",
    "print(f'The total papers are: {len((ref_in_cite))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d862f48e-26a3-43c3-9d4d-4e67fad9d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019 2017 2018 2022 2020 2021]\n"
     ]
    }
   ],
   "source": [
    "## Ensure all articles are from 2018 to 2022\n",
    "unique_years = articles_selected['year:int'].unique()\n",
    "\n",
    "print(unique_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4f8824-338a-4238-a187-a03acfd3aa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free up Memory Allocation\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e443df89-2bf2-4f47-b252-6406f454ee03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f8e9d35-12ea-4984-bc6d-83b8d62c2552",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:AUTHORS NODE) --> [:AUTHORS_WRITES_ARTICLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29eda3f8-a054-484a-b4f6-e37e01fa879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data from Authors\n",
    "\n",
    "## authors\n",
    "authors = pd.read_csv('DXML\\\\output_author.csv',sep=';')\n",
    "\n",
    "## authors writes articles\n",
    "authors_articles = pd.read_csv('DXML\\\\output_author_authored_by.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66f84a43-c6be-41a1-ad3c-e6c9ceaaa2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:ID</th>\n",
       "      <th>author:string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9734485</td>\n",
       "      <td>Oliver Hoffmann 0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9734486</td>\n",
       "      <td>Florian Reitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9734487</td>\n",
       "      <td>Russell Turpin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9734488</td>\n",
       "      <td>Frank Olken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9734489</td>\n",
       "      <td>Guido Frisch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       :ID         author:string\n",
       "0  9734485  Oliver Hoffmann 0002\n",
       "1  9734486         Florian Reitz\n",
       "2  9734487        Russell Turpin\n",
       "3  9734488           Frank Olken\n",
       "4  9734489          Guido Frisch"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.head()\n",
    "#authors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "772e17fa-69bd-476b-a965-f058a1395d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replicate the articles to have atleast 4 different articles with different authors\n",
    "\n",
    "aser = pd.concat([articles_selected[['article:ID', 'author-aux:string']]]*4, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8bebee8-6189-4d67-b778-cc1334cf1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aser.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "232c93bb-5717-4d0a-a989-774ff0ae7c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 1000 authors\n",
    "## Assign to 10000 selected articles to have atleast 4 writers per article type\n",
    "\n",
    "aut_sel = authors[1000:2000]\n",
    "len(aut_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82c2a559-7de1-4e93-ae6e-7b3d4d4a2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign the authors list randomly to articles\n",
    "\n",
    "aut_sel_id = list(set(list(aut_sel[':ID'])))\n",
    "\n",
    "# Define function to randomly assignIDs\n",
    "def assign_no():\n",
    "    return random.choice(aut_sel_id)\n",
    "\n",
    "# Apply function to create edition venue column with randomly assigned cities\n",
    "aser['author-aux:string'] = aser.apply(lambda x: assign_no(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "558fdb63-f625-4cbd-b0cf-652ce08a74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##merge to get author names\n",
    "authors_in_articles_sel = pd.merge(aut_sel, aser, left_on=':ID', right_on='author-aux:string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04665103-050b-4a68-a3d7-ea12cd50e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:ID</th>\n",
       "      <th>author:string</th>\n",
       "      <th>article:ID</th>\n",
       "      <th>author-aux:string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9735485</td>\n",
       "      <td>Sumit Ganguly</td>\n",
       "      <td>6614829</td>\n",
       "      <td>9735485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9735485</td>\n",
       "      <td>Sumit Ganguly</td>\n",
       "      <td>6612305</td>\n",
       "      <td>9735485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9735485</td>\n",
       "      <td>Sumit Ganguly</td>\n",
       "      <td>6616712</td>\n",
       "      <td>9735485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9735485</td>\n",
       "      <td>Sumit Ganguly</td>\n",
       "      <td>6614665</td>\n",
       "      <td>9735485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9735485</td>\n",
       "      <td>Sumit Ganguly</td>\n",
       "      <td>6620184</td>\n",
       "      <td>9735485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       :ID  author:string  article:ID  author-aux:string\n",
       "0  9735485  Sumit Ganguly     6614829            9735485\n",
       "1  9735485  Sumit Ganguly     6612305            9735485\n",
       "2  9735485  Sumit Ganguly     6616712            9735485\n",
       "3  9735485  Sumit Ganguly     6614665            9735485\n",
       "4  9735485  Sumit Ganguly     6620184            9735485"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop duplicates\n",
    "authors_in_articles_sel= authors_in_articles_sel.drop_duplicates(subset=[':ID', 'article:ID'])\n",
    "authors_in_articles_sel.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5577e2d7-c852-40ce-92d1-6f7a6cc1500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39936, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating replica\n",
    "authors_in_articles_sel1 = authors_in_articles_sel.copy()\n",
    "authors_in_articles_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b0f238e-ee2b-4734-a2d6-a95ba6d9d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to str type and rename\n",
    "authors_in_articles_sel['article:IDstr[]'] = authors_in_articles_sel['article:ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "357c2eaf-3dba-4b75-a2fe-2055bafbe2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article:IDstr[]</th>\n",
       "      <th>author:string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4038748</td>\n",
       "      <td>Tomoya Mori|Md-Mizanur Rahoman|Björn Hammarberg|Fredrik Espinoza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4039839</td>\n",
       "      <td>Gustavo Castellano|Ilmiawan Shubhi|Kanae Akaiwa|Tobias Olsson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article:IDstr[]  \\\n",
       "0         4038748   \n",
       "1         4039839   \n",
       "\n",
       "                                                      author:string  \n",
       "0  Tomoya Mori|Md-Mizanur Rahoman|Björn Hammarberg|Fredrik Espinoza  \n",
       "1     Gustavo Castellano|Ilmiawan Shubhi|Kanae Akaiwa|Tobias Olsson  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sample dataframe\n",
    "\n",
    "# group by 'group' column and aggregate values with \"|\"\n",
    "merge_auth = authors_in_articles_sel.groupby('article:IDstr[]')['author:string'].agg('|'.join).reset_index()\n",
    "\n",
    "# print resulting dataframe\n",
    "merge_auth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83b32dff-23e4-4249-99ac-b0390a72bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ID to int type\n",
    "merge_auth['article:IDstr[]'] = merge_auth['article:IDstr[]'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a6ad97-5896-42ed-9c84-15988b2de295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add info to articles_selected for articles\n",
    "articles_selected1 = pd.merge(merge_auth, articles_selected, left_on='article:IDstr[]', \n",
    "                                   right_on='article:ID').drop(columns = [i for i in merge_auth.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee82981b-25a1-4ffc-a5d3-ceb51164066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating replics\n",
    "articles_selected = articles_selected1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1707471f-59c4-4f94-8e9c-c8bff70ecf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns to match Neo4j requirememts\n",
    "\n",
    "authors_in_articles_sel1 = authors_in_articles_sel1[[':ID', 'article:ID']]\n",
    "authors_in_articles_sel1 = authors_in_articles_sel1.rename(columns={':ID': 'authorid', 'article:ID': 'articleid'})\n",
    "\n",
    "authored_with_articles1 = authors_in_articles_sel.copy()\n",
    "authored_with_articles1.rename(columns={':ID': 'authorID'}, inplace=True)\n",
    "authored_with_articles1.drop(columns = ['article:ID','author-aux:string','article:IDstr[]' ], inplace=True)\n",
    "authored_with_articles1.drop_duplicates(subset=['authorID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4cfdc66-23be-4e76-88b0-97b2471c4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "\n",
    "## authors writes articles\n",
    "authors_in_articles_sel1.to_csv(path_or_buf='Mains/authors_writes_articles.csv', index=False, header=True)\n",
    "\n",
    "## authors\n",
    "authored_with_articles1.to_csv(path_or_buf='Mains/authors.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2b9d8cd-18e7-4e72-bdc4-ae877f5d5acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Free memory\n",
    "del authors, authors_articles\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2c90c40-2437-4741-a040-35637ed98b4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2982b303-d947-45cb-a90c-eacc802da8fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:JOURNALS NODE) --> [:PUBLISHED_IN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7f98588-3f37-4c22-860b-27af0b0e41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data from Journals\n",
    "\n",
    "## Journals\n",
    "journals = pd.read_csv('DXML\\\\output_journal.csv',sep=';')\n",
    "\n",
    "## Journals published\n",
    "#articles_in_journals = pd.read_csv('DXML\\\\output_journal_published_in.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b8a27fa-3316-46c2-8cb5-95414c83b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total journals are: 3508\n"
     ]
    }
   ],
   "source": [
    "## fetch journals from article list J\n",
    "fil_journal = articles_selected.loc[articles_selected['sup:string[]'] == 'J']\n",
    "\n",
    "print(f'The total journals are: {(fil_journal.shape[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "102c4d68-1323-4cf1-9e9d-49e2c020e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_journal1 = fil_journal[['article:ID','crossref:string', 'volume:string']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d1b4d9e-2a7e-4c92-afb0-03252426c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting 8 journals for use\n",
    "journals = journals[12:20]\n",
    "\n",
    "#journals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a30cafe7-2807-4e7a-8e40-f4eec4bddf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly like the cite node, assign selected journals to edge\n",
    "\n",
    "ref_in_journal = list(set(list(journals[':ID'])))\n",
    "\n",
    "# Define function to randomly assign city\n",
    "def assign_no():\n",
    "    return random.choice(ref_in_journal)\n",
    "\n",
    "# Apply function to create edition venue column with randomly assigned cities\n",
    "fil_journal1['crossref:string'] = fil_journal1.apply(lambda x: assign_no(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c400f8c7-3d70-4121-a416-92d9bcb194c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns to match Neo4j requirememts\n",
    "fil_journal1 = fil_journal1.rename(columns={'article:ID': 'articleid',\n",
    "                                     'crossref:string': 'journalid'})\n",
    "fil_journal1.drop_duplicates(subset=['articleid'], inplace=True)\n",
    "\n",
    "merged_journals1 = journals.copy()\n",
    "merged_journals1.rename(columns={':ID': 'journalID'}, inplace=True)\n",
    "\n",
    "merged_journals1.drop_duplicates(subset=['journalID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "704d624f-5b1a-4039-a22f-73d0699ae090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "\n",
    "## articles published in journals\n",
    "fil_journal1.to_csv(path_or_buf='Mains/articles_in_journal.csv', index=False, header=True)\n",
    "\n",
    "## journals\n",
    "merged_journals1.to_csv(path_or_buf='Mains/journals.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d231150-bb86-41dd-91cb-81762cd58ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del journals\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4383a7cb-47df-4962-a7e0-13a08d769e82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "106092d5-48e3-4e40-876e-3af37e108192",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:CONFERENCES NODE) --> [:INPROCEEDINGS_OF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4e9835e-43ba-4a68-a643-a724e3d08f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all inproceedings \n",
    "\n",
    "## Article headers\n",
    "with open('DXML\\\\output_inproceedings_header.csv') as f:\n",
    "    proceedings_header = f.readline().split(';');\n",
    "    #print(proceedings_header[1:5])\n",
    "\n",
    "## Number of articles in dataset\n",
    "inproceedings = pd.read_csv('DXML\\\\output_inproceedings.csv', header=0, names=proceedings_header, sep=';');\n",
    "\n",
    "## Display articles\n",
    "#inproceedings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27a98bbf-0546-45f2-81c2-44434ee062bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing Total number of inproceedings\n",
    "\n",
    "## Drop inproceedings columns with more than half null values \n",
    "inproceedings.drop(columns = [i for i in inproceedings.columns if (inproceedings[i].isna().sum() > inproceedings[i].count()/2) == True], inplace = True)\n",
    "\n",
    "## Drop inproceedings rows without author, number or articleID\n",
    "inproceedings.dropna(subset = [i for i in inproceedings.columns], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecdf6e2c-b01d-4eae-8528-ded8a119e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fetch journals from article list\n",
    "fil_conf = articles_selected.loc[articles_selected['sup:string[]'] == 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186ea24-b211-491e-a889-cc6f71e9feb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "211ba9fa-28dc-4138-8116-098eb09b32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly like the cite node, assign selected conferences to edge\n",
    "\n",
    "fil_conf = list(set(list(fil_conf['article:ID'])))\n",
    "\n",
    "# Define function to randomly assign\n",
    "def assign_no():\n",
    "    return random.choice(fil_conf)\n",
    "\n",
    "# Apply function to create edition venue column with randomly assigned cities\n",
    "inproceedings[':START_ID'] = inproceedings.apply(lambda x: assign_no(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104bd8c-18d3-4ead-863d-e1d1edfb3357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63665b05-37c0-46f1-b2de-be7dbb3f4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign edition numbers\n",
    "\n",
    "Conf_no = ['9999|ECIS|European Conference on Information Systems (ECIS)',\n",
    "           '8888|ECSW|European Conference on Computer-Supported Cooperative Work (ECSCW)',\n",
    "           '7777|ECHI|European Conference on Human-Computer Interaction (ECHI)',\n",
    "           '6666|ECIR|European Conference on Information Retrieval (ECIR)',\n",
    "           '5555|ECAI|European Conference on Artificial Intelligence (ECAI)',\n",
    "           '4444|IEEE|International Conference on Data Mining (ICDM)',\n",
    "           '3333|ICML|International Conference on Machine Learning (ICML)',\n",
    "           '2222|IJCAI|International Joint Conference on Artificial Intelligence (IJCAI)']\n",
    "\n",
    "\n",
    "\n",
    "# Define function to randomly assign city\n",
    "def assign_no():\n",
    "    return random.choice(Conf_no)\n",
    "\n",
    "# Apply function to create edition venue column with randomly assigned cities\n",
    "inproceedings['Conf_no'] = inproceedings.apply(lambda x: assign_no(), axis=1)\n",
    "\n",
    "\n",
    "inproceedings[['inproceedings:ID','Conf:string', 'ConfName:string']] = inproceedings['Conf_no'].str.split(\"|\", expand = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8fb28d6-2e81-40dc-bb7d-8dc68611ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "inproceedings.drop_duplicates(subset=[':START_ID'], inplace=True)\n",
    "\n",
    "# make copies for edge\n",
    "articles_sel_in_inproceedings = inproceedings.copy()\n",
    "\n",
    "## copy articles in node\n",
    "sel_inproceedings = articles_sel_in_inproceedings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f9c28fe-f220-4ea3-b36a-d09773618abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unneccesary columns for edge\n",
    "drop_col = ['author:string[]', 'booktitle:string', 'crossref:string[]', \n",
    "            'ee:string[]', 'key:string', 'mdate:date','pages:string', \n",
    "            'title:string', 'url:string', 'year:int',]\n",
    "\n",
    "sel_inproceedings.drop(columns=drop_col, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39eee63d-9413-4769-9bfc-8fb6e4d641c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unneccesary\n",
    "drop_col = ['year:int', ':START_ID']\n",
    "\n",
    "articles_sel_in_inproceedings.drop(columns=drop_col, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06badeef-3bc4-421a-b5cf-1f8375edce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign edition numbers\n",
    "\n",
    "editions_no = ['Barcelona|1', 'Brussels|2', 'Milan|3', 'Amsterdam|4']\n",
    "\n",
    "\n",
    "\n",
    "# Define function to randomly assign city\n",
    "def assign_no():\n",
    "    return random.choice(editions_no)\n",
    "\n",
    "# Apply function to create edition venue column with randomly assigned cities\n",
    "articles_sel_in_inproceedings['edt'] = articles_sel_in_inproceedings.apply(lambda x: assign_no(), axis=1)\n",
    "\n",
    "\n",
    "articles_sel_in_inproceedings[['edtVen:string', 'edtNum:int']] = articles_sel_in_inproceedings['edt'].str.split(\"|\", expand = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "481f64d4-bf5c-4f49-9ca4-ba18419fb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns to match Neo4j requirememts\n",
    "\n",
    "sel_inproceedings1 = sel_inproceedings.copy().rename(\n",
    "    columns={':START_ID': 'articleid', 'inproceedings:ID': 'conferenceid'})\n",
    "\n",
    "sel_inproceedings1 = sel_inproceedings1[['articleid', 'conferenceid']]\n",
    "sel_inproceedings1.drop_duplicates(subset=['articleid'], inplace=True)\n",
    "\n",
    "\n",
    "articles_sel_in_inproceedings1 = articles_sel_in_inproceedings.copy()\n",
    "articles_sel_in_inproceedings1.rename(columns={'inproceedings:ID':'conferenceID',\n",
    "                                               'mdate:date':'edtyear:date', 'booktitle:string': 'edtTitle:string'}, inplace=True)\n",
    "articles_sel_in_inproceedings1.drop(columns = ['author:string[]', 'edt', 'Conf_no'], inplace=True)\n",
    "articles_sel_in_inproceedings1.drop_duplicates(subset=['conferenceID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e756256-769b-48f2-8225-0e55988331b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conferenceID</th>\n",
       "      <th>edtTitle:string</th>\n",
       "      <th>crossref:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>key:string</th>\n",
       "      <th>edtyear:date</th>\n",
       "      <th>pages:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>url:string</th>\n",
       "      <th>Conf:string</th>\n",
       "      <th>ConfName:string</th>\n",
       "      <th>edtVen:string</th>\n",
       "      <th>edtNum:int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4444</td>\n",
       "      <td>CoopIS</td>\n",
       "      <td>conf/coopis/2000</td>\n",
       "      <td>https://doi.org/10.1007/10722620_29</td>\n",
       "      <td>conf/coopis/ChenD00</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>311-322</td>\n",
       "      <td>Multi-Agent Cooperative Transactions for E-Commerce.</td>\n",
       "      <td>db/conf/coopis/coopis2000.html#ChenD00</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>International Conference on Data Mining (ICDM)</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  conferenceID edtTitle:string crossref:string[]  \\\n",
       "0         4444          CoopIS  conf/coopis/2000   \n",
       "\n",
       "                           ee:string[]           key:string edtyear:date  \\\n",
       "0  https://doi.org/10.1007/10722620_29  conf/coopis/ChenD00   2017-05-24   \n",
       "\n",
       "  pages:string                                          title:string  \\\n",
       "0      311-322  Multi-Agent Cooperative Transactions for E-Commerce.   \n",
       "\n",
       "                               url:string Conf:string  \\\n",
       "0  db/conf/coopis/coopis2000.html#ChenD00        IEEE   \n",
       "\n",
       "                                  ConfName:string edtVen:string edtNum:int  \n",
       "0  International Conference on Data Mining (ICDM)      Brussels          2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_sel_in_inproceedings1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c09b3511-ee58-4f68-b377-849ad119cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to CSV\n",
    "\n",
    "# articles_inproceedings_conferences\n",
    "sel_inproceedings1.to_csv(path_or_buf='Mains/articles_in_conferences.csv', index=False, header=True)\n",
    "\n",
    "# conferences\n",
    "articles_sel_in_inproceedings1.to_csv(path_or_buf='Mains/conferences.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7842c98-d969-4265-a15a-9632831b8c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del inproceedings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7acc37fe-95ff-4c1c-be15-0866ae0558e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac6e1067-263a-4245-8d64-7ccc806ac69b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:REVIEWERS NODE) --> [:REVIEWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9cbb8f1-0a2e-4e31-9465-2642c4d4e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## articles for reviews \n",
    "art_rev_selected = articles_selected[['article:ID', 'author:string[]', 'title:string']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d0fb8ec-dc94-4638-933b-670df53e3b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elias Koutsoupias', 'Choon Yik Tang', 'Joseph E. Stoy', 'Charika De Alvis']\n"
     ]
    }
   ],
   "source": [
    "# Creating list of reviewers\n",
    "\n",
    "split_authors = art_rev_selected['author:string[]'].str.split(\"|\", expand=True)\n",
    "\n",
    "authors_list = []\n",
    "\n",
    "for i in split_authors[split_authors.columns[0]].values.tolist():\n",
    "    authors_list.append(i)\n",
    "        \n",
    "my_auth_list = list(set(list(authors_list)))\n",
    "print(my_auth_list[4:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e754fee-7781-4164-bdc7-7a26a4f794d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan from first column\n",
    "my_auth_list = my_auth_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a094d08-9276-4fec-acdf-e065640b0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Duplicate art_rev_selected thrice because we assume that every articles must have at least 3 reviews\n",
    "art_rev_selected = pd.concat([art_rev_selected]*3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b94e9e1-84ee-4ca3-b327-795328acd782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>title:string</th>\n",
       "      <th>reviewer_name:string[]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4038748</td>\n",
       "      <td>Clement T. Yu|Hai He|Weiyi Meng|Yiyao Lu|Zonghuan Wu</td>\n",
       "      <td>Towards Deeper Understanding of the Search Interfaces of the Deep Web.</td>\n",
       "      <td>Alvis Brazma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article:ID                                       author:string[]  \\\n",
       "0     4038748  Clement T. Yu|Hai He|Weiyi Meng|Yiyao Lu|Zonghuan Wu   \n",
       "\n",
       "                                                             title:string  \\\n",
       "0  Towards Deeper Understanding of the Search Interfaces of the Deep Web.   \n",
       "\n",
       "  reviewer_name:string[]  \n",
       "0           Alvis Brazma  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Assigning authors list to reviews\n",
    "random.seed(42)\n",
    "\n",
    "# define list of values to randomly assign\n",
    "my_list = my_auth_list\n",
    "\n",
    "# define function to randomly assign value from list to new column, avoiding strings\n",
    "def assign_value(row, my_list):\n",
    "    new_value = random.choice(my_list)\n",
    "    while any([str(new_value) in str(x) for x in row.values]):\n",
    "        new_value = random.choice(my_list)\n",
    "    return new_value\n",
    "\n",
    "# set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# apply function to create new column with randomly assigned values\n",
    "art_rev_selected['reviewer_name:string[]'] = art_rev_selected.apply(lambda row: assign_value(row, my_list), axis=1)\n",
    "\n",
    "# print resulting dataframe\n",
    "art_rev_selected.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "430c2f48-e928-4f69-90c3-910c5d613db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>title:string</th>\n",
       "      <th>reviewer_name:string[]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [article:ID, author:string[], title:string, reviewer_name:string[]]\n",
       "Index: []"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confirm it was well assigned\n",
    "filtered_df = art_rev_selected.loc[art_rev_selected['article:ID'] == 6667990]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b79eb4a8-3c6b-4358-94d1-2b501ad4e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reviews using Lorem library\n",
    "review_comm = []\n",
    "\n",
    "for i in range(art_rev_selected.shape[0]):\n",
    "    review_comm.append(lorem.sentence())\n",
    "        \n",
    "art_rev_selected['reviews:string'] = review_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a98ccbb-0cec-4e30-8193-3441e3d91402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning IDs to eachh reviews\n",
    "art_rev_selected['reviewID:ID(reviewID)'] = range(999, len(art_rev_selected)+999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4ce8ffc-fe44-4774-a2e2-98c932ecf99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that if majority of the papers are accepted then it is published.\n",
    "## we assume all papers are accepted but with a ditribution of 95% for True (accepted)\n",
    "art_rev_selected['accepted:boolean'] = np.random.choice([True, False], size=len(art_rev_selected), p=[0.95, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd43d553-9b93-4e95-9b2e-074ac7ad91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns to match Neo4j requirememts\n",
    "\n",
    "art_rev_selected['article:ID'] = art_rev_selected['article:ID'].astype(int)\n",
    "\n",
    "article_in_reviews = art_rev_selected[['article:ID', 'reviewID:ID(reviewID)']]\n",
    "\n",
    "article_in_reviews = article_in_reviews.rename(\n",
    "    columns={'article:ID': 'articleid', 'reviewID:ID(reviewID)': 'reviewid'})\n",
    "\n",
    "reviews = art_rev_selected[['reviewID:ID(reviewID)', 'article:ID', 'author:string[]', 'title:string',\n",
    "                            'reviewer_name:string[]', 'reviews:string', 'accepted:boolean']]\n",
    "reviews.rename(columns={'reviewID:ID(reviewID)':'reviewID' ,'article:ID': 'articleID:int'}, inplace=True)\n",
    "reviews.drop_duplicates(subset=['reviewID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13da8c7a-7bb1-4a21-bb22-74280fd26250",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to CSV\n",
    "article_in_reviews.to_csv(path_or_buf='Mains/reviews_in_articles.csv', index=False, header=True)\n",
    "\n",
    "reviews.to_csv(path_or_buf='Mains/reviews.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "409664dc-f90f-411a-98fd-40efa1a113da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del art_rev_selected\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464ae6b-76b1-4a20-a6d0-c79f3b19230d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "348ba791-bc76-49c0-8598-b822ab9f0859",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### {ADDING ABSTRACTS TO ARTICLES & CORRESPONDING AUTHOR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e1aa2ed-b18d-4a8f-bcb5-b90f5a0f04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating abstracts using Lorem library\n",
    "abstracts = []\n",
    "\n",
    "for i in range(articles_selected.shape[0]):\n",
    "    abstracts.append(lorem.paragraph())\n",
    "        \n",
    "articles_selected['abstract:string'] = abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e39fe7b1-88ee-4281-a311-5c97edd6511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding titles to Abstracts so that it contains good keywords\n",
    "\n",
    "articles_selected['title:string'] = articles_selected['title:string'].astype(str)\n",
    "articles_selected['abstract:string'] = articles_selected[['abstract:string', 'title:string']].agg(' '.join, axis=1)\n",
    "articles_selected[\"corresponding_author:string\"] = articles_selected[\"author:string[]\"].str.split(\"|\", expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0bf815a-2861-45b5-8283-674c233c444f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article:ID', 'author:string[]', 'author-aux:string',\n",
       "       'author-orcid:string[]', 'booktitle:string', 'cdate:date',\n",
       "       'cdrom:string', 'cite:string[]', 'cite-label:string[]',\n",
       "       'crossref:string', 'editor:string[]', 'editor-orcid:string[]',\n",
       "       'ee:string[]', 'ee-type:string[]', 'i:string[]', 'journal:string',\n",
       "       'key:string', 'mdate:date', 'month:string', 'note:string[]',\n",
       "       'note-label:string', 'note-type:string[]', 'number:string',\n",
       "       'pages:string', 'publisher:string', 'publnr:string', 'publtype:string',\n",
       "       'sub:string[]', 'sup:string[]', 'title:string', 'title-bibtex:string',\n",
       "       'tt:string[]', 'url:string[]', 'volume:string', 'year:int',\n",
       "       'abstract:string', 'corresponding_author:string'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_selected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8868ebf-1726-42c6-8eb8-b628a7e66b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instance for citation\n",
    "articles_insta = articles_selected[['article:ID','author:string[]', 'title:string', 'year:int']]\n",
    "\n",
    "articles_insta.rename(columns={'article:ID':'citaID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b94e55a6-6bb4-486e-9f16-5c763b3dd089",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns to match Neo4j requirememts\n",
    "articles_selected.rename(columns={'article:ID':'articleID','mdate:date':'edtyear:string[]','sup:string[]':'sup' }, inplace=True)\n",
    "\n",
    "articles_selected.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "articles_selected.drop_duplicates(subset=['articleID'], inplace=True)\n",
    "\n",
    "articles_selected['year:int'] = articles_selected['year:int'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19506bda-a1cc-4652-8465-f020dee6ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "\n",
    "## Articles instances \n",
    "articles_selected.to_csv(path_or_buf='Mains/articles.csv', index=False, header=True)\n",
    "\n",
    "#citation\n",
    "articles_insta.to_csv(path_or_buf='Mains/citation.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de0347df-9fd3-4161-918a-04dde6348e2b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4104ca06-9fda-4c78-9862-e80bcfce303b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:KEYWORDS NODE) --> [:CONTAINS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99f5c865-739d-47eb-bd61-eee267badf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate KEYWORDS from titles/abstract of articles to add for the community\n",
    "\n",
    "split_title = articles_selected[\"title:string\"].str.split(\" \", expand=True)\n",
    "\n",
    "kwords = []\n",
    "\n",
    "## words with lenght 15\n",
    "for i in split_title[split_title.columns[0]].values.tolist():\n",
    "    if len(i)==15:\n",
    "        kwords.append(i)\n",
    "        \n",
    "my_list = list(set(list(kwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e09b1764-45d0-49ce-88eb-32cdbc74dc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Proxy-invisible', 'Label-Selective', 'Query-monotonic', 'Polynomial-Time']\n"
     ]
    }
   ],
   "source": [
    "# Filter out words containing non-ASCII characters\n",
    "my_list = [word for word in my_list if all(ord(char) < 128 for char in word)]\n",
    "\n",
    "print(my_list[4:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb5ae91c-6e6f-4035-88dd-417bf424f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding more keywords from exercises so that least 90% is contained from this \n",
    "db_keywords = ['data management', 'indexing', 'data modeling', 'big data', 'data processing',\n",
    "               'data storage', 'data querying']\n",
    "\n",
    "# Combine list \n",
    "combined_list = db_keywords + my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8cbbbeb2-e17c-41c8-a763-985c265455a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with randomly assigned values\n",
    "def assign_value():\n",
    "    if random.random() < 0.95:\n",
    "        return random.choice(db_keywords)\n",
    "    else:\n",
    "        return random.choice(my_list)\n",
    "\n",
    "aser['author-aux:string'] = aser.apply(lambda x: assign_value(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55db22dd-90fc-4b71-bd50-27485f3cbcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame for kwords and add ID column \n",
    "kword = pd.DataFrame(combined_list, columns=['word:string'])\n",
    "kword = kword.reset_index(drop=False)\n",
    "kword['keywordID:ID(keywordID)'] = kword.index + 999\n",
    "\n",
    "# Print resulting DataFrame\n",
    "len(kword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "068ac3a8-cc43-4293-908c-26627b23e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "##merge to obtain articles\n",
    "\n",
    "aser_sel = pd.merge(kword, aser, left_on='word:string', right_on='author-aux:string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6717abfc-6fae-4285-b8df-e34ccbc0add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns to match Neo4j requirememts\n",
    "aser = aser_sel[['article:ID','keywordID:ID(keywordID)']]\n",
    "aser.rename(columns={'article:ID': 'articleid', 'keywordID:ID(keywordID)': 'keywordid'},inplace=True)\n",
    "aser.drop_duplicates(subset=['articleid','keywordid'], inplace=True)\n",
    "\n",
    "keywords = kword[['keywordID:ID(keywordID)','word:string']]\n",
    "keywords.rename(columns={'keywordID:ID(keywordID)': 'keywordID'},inplace=True)\n",
    "keywords.drop_duplicates(subset=['keywordID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "182e0c96-c306-4ce8-be0d-2b828965e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "## keywords\n",
    "keywords.to_csv(path_or_buf='Mains\\\\keywords.csv', index=False, header=True)\n",
    "\n",
    "## articles with keywords\n",
    "aser.to_csv(path_or_buf='Mains\\\\article_keywords.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ac1ca58-e3e0-4407-83a4-d46cd479a66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del article_keywords, keywords\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09e37cf9-a206-494c-8dc8-e933dd7dd35d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0028bcdf-5b39-40f2-ba2f-be886e32ebde",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### (:UNIVERSITIES NODE) --> [:AFFILIATED_IN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "554433df-14c8-4e26-82d0-1fe7c7e0f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all dataset from school\n",
    "\n",
    "## Universities\n",
    "school = pd.read_csv('DXML\\\\output_school.csv',sep=';')\n",
    "\n",
    "## Affiliates\n",
    "output_school_submitted_at = pd.read_csv('DXML\\\\output_school_submitted_at.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48272f02-cf1a-45b6-9428-3ea25f519bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly assign authors to a schools\n",
    "## Assuming the authors are affiliated to only schools all across the world\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# define list of values to randomly assign\n",
    "my_list = list(set(list(authors_in_articles_sel1['authorid'])))\n",
    "\n",
    "\n",
    "# define function to randomly assign value from list to new column, avoiding repition\n",
    "def assign_value(row, my_list):\n",
    "    new_value = random.choice(my_list)\n",
    "    while any([str(new_value) in str(x) for x in row.values]):\n",
    "        new_value = random.choice(my_list)\n",
    "    return new_value\n",
    "\n",
    "# set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# apply function to create new column with randomly assigned values\n",
    "output_school_submitted_at[':START_ID(authorID)'] = output_school_submitted_at.apply(lambda row: assign_value(row, my_list), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08b05c36-2266-4ffb-a00a-0e67f9acb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge wtih affiliated\n",
    "output_school_submitted_at = output_school_submitted_at[[':START_ID(authorID)',':END_ID']].rename(columns={':START_ID(authorID)':'authorid', ':END_ID': 'schoolid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18299d66-3d57-4586-a36f-8be587f6b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Rename columns to match Neo4j requirememts\n",
    "\n",
    "school.rename(columns={':ID': 'schoolID'}, inplace=True)\n",
    "\n",
    "school.drop_duplicates(subset=['schoolID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3e9ccb0-c3e9-47af-958b-ba86aa902bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "\n",
    "## author_affiliated_school\n",
    "output_school_submitted_at.to_csv(path_or_buf='Mains/author_affiliated_school.csv', index=False, header=True)\n",
    "\n",
    "## Universities\n",
    "school.to_csv(path_or_buf='Mains/school.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a95c51f-212e-43f9-a519-0a0e54435dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del output_school_submitted_at, school\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdb774e4-5285-4f53-92f7-1af44643ae1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e99a15c-80a8-4dce-bfe6-437e2e5ec604",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generated CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "782d0fc0-21cb-4292-937f-2ede08c5643e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mains\\\\articles.csv',\n",
       " 'Mains\\\\articles_in_conferences.csv',\n",
       " 'Mains\\\\articles_in_journal.csv',\n",
       " 'Mains\\\\article_keywords.csv',\n",
       " 'Mains\\\\authors.csv',\n",
       " 'Mains\\\\authors_writes_articles.csv',\n",
       " 'Mains\\\\author_affiliated_school.csv',\n",
       " 'Mains\\\\citation.csv',\n",
       " 'Mains\\\\cite_has_citation.csv',\n",
       " 'Mains\\\\conferences.csv',\n",
       " 'Mains\\\\journals.csv',\n",
       " 'Mains\\\\keywords.csv',\n",
       " 'Mains\\\\reviews.csv',\n",
       " 'Mains\\\\reviews_in_articles.csv',\n",
       " 'Mains\\\\school.csv']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All CSV files generated from after pre-processing\n",
    "## All files and directories ending with .csv:\n",
    "files = (glob.glob(\"Mains/*.csv\"))\n",
    "\n",
    "#Generated files names\n",
    "files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
